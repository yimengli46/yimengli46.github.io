<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yimeng Li</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yimeng Li</name>
              </p>
              <p>I am a PhD Candidate at <a href="http://cs.gmu.edu/">George Mason University</a>, where I work on computer vision and robotics.
              My advisor is Prof. <a href="http://cs.gmu.edu/~kosecka">Jana Kosecka</a>. 
              I have worked on two problems, visual navigation on indoor scenes and out-of-dist object detection.
              </p>
              <p> In the summer of 2020 I did an internship with Dr. <a href='https://www.linkedin.com/in/huangjiawei/'>Jiawei Huang</a> at HRI, US where I worked on 3d object detection with stereo. 
              I spent one summer at AFRL MMOI as an intern working on aerial images. 
              </p>
              <p> Prior to joining George Mason University, I received my B.E. in Software Engineering in 2014 from East China Normal University, Shanghai.
              </p>

              <p style="text-align:center">
                <a href="mailto:yli44@gmu.edu">Email</a> &nbsp/&nbsp
                <a href="data/LI_Yimeng_cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=gOLPBtMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/yimeng-li-423666102/"> LinkedIn </a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Yimeng.JPG"><img style="width:65%;max-width:100%" alt="profile photo" src="images/Yimeng.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, robotics and deep reinforcement learning. My research is about visual navigation.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
        <!-- CoRL 2022 Workshop -->
        <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
              <img src='images/corl2022_workshop.gif' width="256">
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=2s92OhjT4L">
                <papertitle>Comparison of Model-Free and Model-Based Learning-Informed Planning for PointGoal Navigation</papertitle>
              </a>
              <br>
              <strong>Yimeng Li</strong>,
              <a>Arnab Debnath</a>,
              <a href="https://cs.gmu.edu/~gjstein/">Gregory Stein</a>,
              <a href="http://cs.gmu.edu/~kosecka">Jana Kosecka</a>
              <br>
              <em>CoRL 2022 LHP Workshop</em>
              <br>
              <a href=Projects/CoRL2022LHPWorkshop/index.html>Project Page</a> /
              <a href="https://youtu.be/Pq4edWdwD98">Presentation</a> /
              <a href="https://docs.google.com/presentation/d/11Y_bdnnj_IHjWWlCzWGxzHsNcGu4tV5g/edit?usp=share_link&ouid=117534998056602904632&rtpof=true&sd=true">Slides</a> /
              <p></p>
              <p>We compare LSP-UNet (a model-based approach) against an optimistic planner, ANS and DD-PPO on Matterport3D dataset using the Habitat Simulator.</p>
            </td>
        </tr>
        
        <!-- Visual Exploration -->
        <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
              <img src='images/icra2023_dp.gif' width="256">
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2211.07898">
                <papertitle>Learning-Augmented Model-Based Planning for Visual Exploration</papertitle>
              </a>
              <br>
              <strong>Yimeng Li</strong>,
              <a>Arnab Debnath</a>,
              <a href="https://cs.gmu.edu/~gjstein/">Gregory Stein</a>,
              <a href="http://cs.gmu.edu/~kosecka">Jana Kosecka</a>
              <br>
              <em>arXiv:2211.07898</em>
              <br>
              <a href=Projects/ICRA2023Exploration/index.html>Project Page</a> /
              <a href="https://youtu.be/vTr01A6Jna4">Presentation</a> /
              <a href="https://docs.google.com/presentation/d/1ceMGVBJxlq4U2ddRb3mwPh83xcpWHFZc/edit?usp=share_link&ouid=117534998056602904632&rtpof=true&sd=true">Slides</a> /
              <p></p>
              <p>We consider the problem of time-limited robotic exploration in previously unseen environments. We propose a novel exploration approach using learning-augmented model-based planning.</p>
            </td>
        </tr>
        
        <!-- Sulabh's Semantic Segmentation -->
         <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/Sulabh_selfSupervise.png' width="256">
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2210.01884">
                <papertitle>Self-supervised Pre-training for Semantic Segmentation in an Indoor Scene</papertitle>
              </a>
              <br>
              <a href="https://github.com/sulabh-shr">Sulabh Shrestha</a>,
              <strong>Yimeng Li</strong>,
              <a href="http://cs.gmu.edu/~kosecka">Jana Kosecka</a>
              <br>
              <em>arXiv:2210.01884</em>
              <br>
              <p></p>
              <p>We propose a method for self-supervised pre-training of a semantic segmentation model, exploiting the ability of the agent to move and register multiple views in the novel environment.</p>
            </td>
        </tr>
        
        <!-- Civil Engineering -->
        <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
                <img src='images/guardrails.jpg' width="256">
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2209.13137">
                <papertitle>Using Unmanned Aerial Systems (UAS) for Assessing and Monitoring Fall Hazard Prevention Systems in High-rise Building Projects</papertitle>
              </a>
              <br>
              <strong>Yimeng Li</strong>,
              <a href="https://scholar.google.com/citations?user=5pFd9AsAAAAJ&hl=en">Behzad Esmaeili</a>,
              <a href="https://scholar.google.com.my/citations?user=UIp-r6YAAAAJ&hl=en">Masoud Gheisari</a>,
              <a href="http://cs.gmu.edu/~kosecka">Jana Kosecka</a>,
              <a href="https://scholar.google.com/citations?user=u_ble2QAAAAJ&hl=en">Abbas Rashidi</a>
              <br>
              <em>arXiv:2209.13137</em>
              <br>
              <p></p>
              <p> This study develops a framework for using unmanned aerial systems (UASs) to monitor fall hazard prevention systems near unprotected edges and openings in high-rise buildings.</p>
            </td>
        </tr>

        <!-- OOD Object Detection -->
        <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
              <img src='images/ood_object.png' width="256">
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2111.12866">
                <papertitle>Uncertainty Aware Proposal Segmentation for Unknown Object Detection</papertitle>
              </a>
              <br>
              <strong>Yimeng Li</strong>,
              <a href="http://cs.gmu.edu/~kosecka">Jana Kosecka</a>
              <br>
              <em>WACV 2022 DNOW Workshop</em>
              <br>
              <a href="https://docs.google.com/presentation/d/1Xbn3Uk2psf_t385mkswDr-Q_ZqjdJTLo/edit?usp=sharing&ouid=117534998056602904632&rtpof=true&sd=true">Slides</a>
              <p></p>
              <p>Detect unknown out-of-dist objects from outdoor scenes. We adapt distance aware uncertainty estimation of semantic segmentation using Radial Basis Functions Networks (RBFN) for class agnostic object mask prediction. </p>
            </td>
        </tr>
        
        <!-- George's mapping -->
        <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
              <img src='images/mapNet.png' width="256">
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1911.07980">
                <papertitle>Simultaneous Mapping and Target Driven Navigation</papertitle>
              </a>
              <br>
              <a href="https://cs.gmu.edu/~ggeorgak/">Georgios Georgakis</a>,
              <strong>Yimeng Li</strong>,
              <a href="http://cs.gmu.edu/~kosecka">Jana Kosecka</a>
              <br>
              <em>arXiv:1911.07980</em>
              <br>
              <a href="https://drive.google.com/file/d/1-Ctsi-_nuc5RwiRVHnvlrtTDkTa8cjfR/view?usp=sharing">Video</a>
              <p></p>
              <p>This work presents a modular architecture for simultaneous mapping and target driven navigation in indoors environments.</p>
            </td>
        </tr>
        
        <!-- visual servoing -->
        <tr>
            <td style="padding:20px;width:35%;vertical-align:middle">
              <img src='images/visual_servoing.gif' width="256">
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2003.02327">
                <papertitle>Learning View and Target Invariant Visual Servoing for Navigation</papertitle>
              </a>
              <br>
              <strong>Yimeng Li</strong>,
              <a href="http://cs.gmu.edu/~kosecka">Jana Kosecka</a>
              <br>
              <em>ICRA, 2020</em>
              <br>
              <a href=Projects/ICRA2020/index.html>Project Page</a> /
              <a href="https://youtu.be/PeMaSIKzPGc">Video</a> /
              <a href="https://youtu.be/MdAb3BoB2VA">Presentation</a> /
              <a href="https://drive.google.com/file/d/1KlNa1M6XTyqa3gFhxsNU0u6Q3jA3_jTw/view?usp=sharing">Slides</a> /
              <a href="https://github.com/GMU-vision-robotics/View-Invariant-Visual-Servoing-for-Navigation">Code</a>
              <p></p>
              <p>Given an initial view and the goal view or an image of the target, we learn viewpoint invariant and target invariant visual servoing for mobile robot navigation.</p>
            </td>
        </tr>
  
        </tbody></table>
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                        <tr>
                            <td style="padding:0px">
                                <br>
                                <p style="text-align:right;font-size:small;">
                                    Yep it's another <a href="https://jonbarron.info/">Jon Barron</a> website.
                                </p>
                            </td>
                        </tr>
                    </tbody>
                </table>

      </td>
    </tr>
  </table>
</body>
  

</html>
